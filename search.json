[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Stock Market Volatility: Patterns and Predictions",
    "section": "",
    "text": "Your report will go here.\n\n# this is a test code",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Report</span>"
    ]
  },
  {
    "objectID": "src/Group Work-Stock Market-IMF.html",
    "href": "src/Group Work-Stock Market-IMF.html",
    "title": "\n2  Stock Market Volatility: Patterns and Predictions\n",
    "section": "",
    "text": "2.1 Team Members",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Stock Market Volatility: Patterns and Predictions</span>"
    ]
  },
  {
    "objectID": "src/Group Work-Stock Market-IMF.html#team-members",
    "href": "src/Group Work-Stock Market-IMF.html#team-members",
    "title": "\n2  Stock Market Volatility: Patterns and Predictions\n",
    "section": "",
    "text": "Zhijun He\nPhoebe Pan",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Stock Market Volatility: Patterns and Predictions</span>"
    ]
  },
  {
    "objectID": "src/Group Work-Stock Market-IMF.html#introduction",
    "href": "src/Group Work-Stock Market-IMF.html#introduction",
    "title": "\n2  Stock Market Volatility: Patterns and Predictions\n",
    "section": "\n2.2 Introduction",
    "text": "2.2 Introduction\nIn today’s interconnected global economy, understanding stock market volatility is not merely an academic exercise but a practical necessity for investors, financial institutions, and policymakers. Our project delves into the fascinating world of market fluctuations, examining how major economic, political, and global events impact market volatility across different sectors from 2000 to 2025.\nThe past quarter-century has witnessed remarkable shifts in global markets—from the dot-com bubble burst to the 2008 financial crisis, from Brexit to the COVID-19 pandemic. Each of these events has left its unique imprint on market volatility patterns. By analyzing these patterns systematically, we aim to unveil the underlying dynamics that drive market turbulence and identify potential predictive indicators.\nMarket volatility—the statistical measure of the dispersion of returns for a given security or market index—serves as a barometer for investor sentiment and economic uncertainty. High volatility periods often reflect heightened uncertainty and risk aversion, while low volatility generally indicates market confidence and stability. The chart below illustrates this relationship by showing the S&P 500 index performance alongside its volatility metric (VIX) from 2000-2025:\n\n# Create data visualization of S&P 500 and VIX relationship\n# First, we'll need to calculate volatility since it doesn't exist in the dataframe\n\nsp500_data &lt;- tq_get(\"^GSPC\", \n                     from = \"2000-01-01\", \n                     to   = \"2025-01-01\", \n                     get  = \"stock.prices\")\n\n\nnormalized_data &lt;- sp500_data %&gt;%\n  mutate(normalized_price = adjusted / first(adjusted) * 100)\n\n\n# Filter for S&P 500 data\nsp500_data &lt;- normalized_data %&gt;%\n  filter(symbol == \"^GSPC\") %&gt;%\n  select(date, adjusted) %&gt;%\n  arrange(date)\n\n# Calculate returns first (percent change from previous day)\nsp500_data &lt;- sp500_data %&gt;%\n  mutate(\n    returns = (adjusted / lag(adjusted) - 1)\n  )\n\n# Now calculate volatility using a 21-day rolling window\nsp500_vix &lt;- sp500_data %&gt;%\n  mutate(\n    volatility = rollapply(returns, width = 21, \n                          FUN = function(x) sd(x, na.rm = TRUE) * sqrt(252),\n                          fill = NA, align = \"right\")\n  ) %&gt;%\n  rename(sp500 = adjusted) %&gt;%\n  # Remove NAs from the calculated volatility\n  filter(!is.na(volatility))\n\n# Create the plot\nggplot(sp500_vix, aes(x = date)) +\n  geom_line(aes(y = sp500, color = \"S&P 500\")) +\n  geom_line(aes(y = volatility * 1000, color = \"Volatility\")) +\n  scale_y_continuous(\n    name = \"S&P 500 Index\",\n    sec.axis = sec_axis(~./1000, name = \"21-day Volatility (Annualized)\")\n  ) +\n  scale_color_manual(values = c(\"S&P 500\" = \"blue\", \"Volatility\" = \"red\")) +\n  labs(\n    title = \"S&P 500 Index and Volatility (2000-2025)\",\n    x = \"Year\",\n    color = \"Metric\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.title.y.left = element_text(color = \"blue\"),\n    axis.title.y.right = element_text(color = \"red\")\n  )\n\n\n\n\n\n\n\nThis visualization captures the dynamic interplay between the S&P 500 Index and market volatility from 2000 to 2025, revealing critical insights for investors and analysts alike. The chart clearly illustrates how volatility typically surges during market downturns—most notably during the 2008 financial crisis, the 2020 pandemic shock, and several smaller corrections throughout the period. By displaying both metrics simultaneously on a dual-axis scale, we can observe not only the dramatic inverse relationship during crisis periods but also the more subtle patterns during bull markets when volatility occasionally rises despite positive returns. This long-term perspective provides valuable context for understanding market behavior across multiple economic cycles and regulatory environments.\nHowever, our research reveals that this relationship is far more nuanced and complex than commonly understood, with important variations across different types of market events, geographic regions, and economic sectors.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Stock Market Volatility: Patterns and Predictions</span>"
    ]
  },
  {
    "objectID": "src/Group Work-Stock Market-IMF.html#data-collection-and-methodology",
    "href": "src/Group Work-Stock Market-IMF.html#data-collection-and-methodology",
    "title": "\n2  Stock Market Volatility: Patterns and Predictions\n",
    "section": "\n2.3 Data Collection and Methodology",
    "text": "2.3 Data Collection and Methodology\nOur analysis leverages comprehensive data from the International Monetary Fund (IMF) and other financial databases to examine volatility patterns across major global markets. We focused on six key economies: the United States, United Kingdom, Japan, Germany, France, and China. The table below presents the major market indices we tracked for our analysis:\n\n\n\nMarket Indices Used in Volatility Analysis\n\n\n\n\n\n\n\n\nCountry\nIndex.Symbol\nIndex.Name\nData.Range\nTrading.Days\n\n\n\nUnited States\n^GSPC\nS&P 500\n2000-2025\n6\n\n\nUnited Kingdom\n^FTSE\nFTSE 100\n2000-2025\n321\n\n\nJapan\n^N225\nNikkei 225\n2000-2025\n6\n\n\nGermany\n^GDAXI\nDAX\n2000-2025\n289\n\n\nFrance\n^FCHI\nCAC 40\n2000-2025\n6\n\n\nChina\n^HSI\nHang Seng\n2000-2025\n154\n\n\nUnited States\n^GSPC\nS&P 500\n2000-2025\n6\n\n\nUnited Kingdom\n^FTSE\nFTSE 100\n2000-2025\n302\n\n\nJapan\n^N225\nNikkei 225\n2000-2025\n6\n\n\nGermany\n^GDAXI\nDAX\n2000-2025\n283\n\n\nFrance\n^FCHI\nCAC 40\n2000-2025\n6\n\n\nChina\n^HSI\nHang Seng\n2000-2025\n104\n\n\n\n\n\nFor our initial data collection, we utilized the tidyquant package, which provides a seamless interface to financial data sources. This approach allowed us to gather historical stock price data for major market indices:\n\n# Collecting stock market indices data for major markets\nindices &lt;- c(\"^GSPC\", \"^FTSE\", \"^N225\", \"^GDAXI\", \"^FCHI\", \"^HSI\")\nindex_names &lt;- c(\"S&P 500\", \"FTSE 100\", \"Nikkei 225\", \"DAX\", \"CAC 40\", \"Hang Seng\")\n\n# Retrieving data from 2000 to present\nmarket_data &lt;- tq_get(indices,\n                      get = \"stock.prices\",\n                      from = \"2000-01-01\",\n                      to = Sys.Date())\n\n# Associating indices with their respective countries\nmarket_data &lt;- market_data %&gt;%\n  mutate(country = case_when(\n    symbol == \"^GSPC\" ~ \"US\",\n    symbol == \"^FTSE\" ~ \"GB\",\n    symbol == \"^N225\" ~ \"JP\",\n    symbol == \"^GDAXI\" ~ \"DE\",\n    symbol == \"^FCHI\" ~ \"FR\",\n    symbol == \"^HSI\" ~ \"CN\"\n  ))\n\n\n# Create a named vector for better labeling\nindex_names &lt;- c(\"S&P 500\", \"FTSE 100\", \"Nikkei 225\", \"DAX\", \"CAC 40\", \"Hang Seng\")\nnames(index_names) &lt;- c(\"^GSPC\", \"^FTSE\", \"^N225\", \"^GDAXI\", \"^FCHI\", \"^HSI\")\n\n# Calculate normalized prices (starting from 100)\nnormalized_data &lt;- market_data %&gt;%\n  group_by(country,symbol) %&gt;%\n  arrange(date) %&gt;%\n  mutate(\n    normalized_price = adjusted / first(adjusted) * 100,\n    # Add 30-day moving average\n    ma30 = rollmean(normalized_price, 30, fill = NA, align = \"right\"),\n    # Add proper index name\n    index_name = index_names[symbol]\n  ) %&gt;%\n  ungroup()\n\n# Define a color palette for markets\nmarket_colors &lt;- c(\n  \"^GSPC\" = \"#0066CC\",  # US - blue\n  \"^FTSE\" = \"#CC0000\",  # GB - red\n  \"^N225\" = \"#FFCC00\",  # JP - yellow\n  \"^GDAXI\" = \"#000000\", # DE - black\n  \"^FCHI\" = \"#009933\",  # FR - green\n  \"^HSI\" = \"#FF6600\"    # CN - orange\n)\n\n# Create the plot\nggplot(normalized_data, aes(x = date, y = normalized_price, color = symbol)) +\n  geom_line(alpha = 0.4, size = 0.5) +\n  geom_line(aes(y = ma30), size = 1) +\n  facet_wrap(~ index_name, scales = \"free_y\", ncol = 2) +\n  scale_color_manual(\n    values = market_colors,\n    labels = function(x) paste0(index_names[x], \" (\", x, \")\"),\n    name = \"Market Index\"\n  ) +\n  scale_x_date(\n    date_breaks = \"5 years\",\n    date_labels = \"%Y\"\n  ) +\n  labs(\n    title = \"Global Market Indices Performance (2000-Present)\",\n    subtitle = \"Normalized to 100 at the beginning of period, with 30-day moving average\",\n    y = \"Normalized Price (Base = 100)\",\n    x = NULL,\n    caption = \"Data source: Yahoo Finance via tidyquant\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"none\",\n    panel.grid.minor = element_blank(),\n    strip.text = element_text(face = \"bold\", size = 11),\n    plot.title = element_text(face = \"bold\", hjust = 0.5),\n    plot.subtitle = element_text(hjust = 0.5)\n  )\n\n\n\n\n\n\n# Create a second plot showing cumulative returns\ncumulative_returns &lt;- normalized_data %&gt;%\n  group_by(symbol, index_name) %&gt;%\n  summarize(\n    final_value = last(normalized_price, order_by = date),\n    total_return = (final_value / 100 - 1) * 100,\n    .groups = \"drop\"\n  ) %&gt;%\n  arrange(desc(total_return))\n\nggplot(cumulative_returns, \n       aes(x = reorder(index_name, total_return), y = total_return, fill = symbol)) +\n  geom_col() +\n  geom_text(\n    aes(label = paste0(round(total_return, 1), \"%\")),\n    hjust = -0.1,\n    color = \"black\",\n    size = 3.5\n  ) +\n  scale_fill_manual(values = market_colors) +\n  scale_y_continuous(\n    labels = function(x) paste0(x, \"%\"),\n    expand = expansion(mult = c(0, 0.15))\n  ) +\n  labs(\n    title = \"Cumulative Returns by Market (2000-Present)\",\n    x = NULL,\n    y = \"Total Return (%)\"\n  ) +\n  coord_flip() +\n  theme_minimal() +\n  theme(\n    legend.position = \"none\",\n    panel.grid.minor = element_blank(),\n    panel.grid.major.y = element_blank(),\n    axis.text.y = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\nThis chart provides a comprehensive comparison of major global market indices over more than two decades, highlighting their relative performance when normalized to the same starting point. The chart reveals striking divergences in long-term returns across different geographic regions, with the S&P 500 and DAX showing exceptional growth of approximately 400% and 300% respectively, while the Hang Seng has demonstrated considerably more volatility with more modest overall gains. The inclusion of 30-day moving averages helps smooth out short-term fluctuations, making it easier to identify meaningful trends and the synchronized global market reactions to major economic events like the 2008 financial crisis and the 2020 pandemic.\nAfter collecting the raw data, we calculated monthly returns and implemented a rolling volatility measure to quantify market turbulence:\n\n# Calculating monthly returns and volatility\nvolatility_data &lt;- market_data %&gt;%\n  group_by(country) %&gt;%\n  arrange(date) %&gt;%\n  mutate(\n    returns = (adjusted / lag(adjusted)) - 1,\n    volatility = rollapply(returns, width = 21, FUN = sd, fill = NA, align = \"right\", na.rm = TRUE) * sqrt(252)\n  ) %&gt;%\n  ungroup()\n\n\n# Calculating monthly returns and volatility\nvolatility_data &lt;- market_data %&gt;%\n  group_by(symbol, country) %&gt;%\n  arrange(date) %&gt;%\n  mutate(\n    # Daily returns\n    daily_returns = (adjusted / lag(adjusted)) - 1,\n    \n    # 21-day rolling volatility (approximately 1 month of trading days)\n    daily_volatility_21d = rollapply(daily_returns, width = 21, \n                                    FUN = sd, fill = NA, align = \"right\", \n                                    na.rm = TRUE),\n    # Annualized volatility (21-day)\n    annualized_volatility_21d = daily_volatility_21d * sqrt(252),\n    \n    # 63-day rolling volatility (approximately 3 months of trading days)\n    daily_volatility_63d = rollapply(daily_returns, width = 63, \n                                    FUN = sd, fill = NA, align = \"right\", \n                                    na.rm = TRUE),\n    # Annualized volatility (63-day)\n    annualized_volatility_63d = daily_volatility_63d * sqrt(252)\n  ) %&gt;%\n  ungroup()\n\n# Map symbol to index name\nsymbol_to_name &lt;- c(\n  \"^GSPC\" = \"S&P 500\", \n  \"^FTSE\" = \"FTSE 100\", \n  \"^N225\" = \"Nikkei 225\", \n  \"^GDAXI\" = \"DAX\", \n  \"^FCHI\" = \"CAC 40\", \n  \"^HSI\" = \"Hang Seng\"\n)\n\n# Create a simple summary table with volatility statistics\nvolatility_summary &lt;- volatility_data %&gt;%\n  filter(!is.na(annualized_volatility_21d)) %&gt;%\n  group_by(symbol, country) %&gt;%\n  summarize(\n    Min_Vol = min(annualized_volatility_21d) * 100,\n    Avg_Vol = mean(annualized_volatility_21d) * 100,\n    Median_Vol = median(annualized_volatility_21d) * 100,\n    Max_Vol = max(annualized_volatility_21d) * 100,\n    Current_Vol = last(annualized_volatility_21d) * 100,\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    Index = symbol_to_name[symbol],\n    across(Min_Vol:Current_Vol, ~ round(., 2))\n  ) %&gt;%\n  select(\n    Index, Country = country, \n    `Min Vol (%)` = Min_Vol,\n    `Avg Vol (%)` = Avg_Vol,\n    `Median Vol (%)` = Median_Vol,\n    `Max Vol (%)` = Max_Vol,\n    `Current Vol (%)` = Current_Vol\n  )\n\n# Display summary table using base R\nprint(volatility_summary)\n\n# A tibble: 6 × 7\n  Index      Country `Min Vol (%)` `Avg Vol (%)` `Median Vol (%)` `Max Vol (%)`\n  &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;         &lt;dbl&gt;            &lt;dbl&gt;         &lt;dbl&gt;\n1 CAC 40     FR               3.93          19.3             16.7          85.8\n2 FTSE 100   GB               4.04          15.7             13.2          80.0\n3 DAX        DE               4.33          19.8             17.0          82.6\n4 S&P 500    US               3.47          16.4             13.8          96.8\n5 Hang Seng  CN               6.24          21.0             18.4         113. \n6 Nikkei 225 JP               5.77          20.8             18.6         116. \n# ℹ 1 more variable: `Current Vol (%)` &lt;dbl&gt;\n\n# Extract last 30 days of data per index for demonstration\nlast_month_data &lt;- volatility_data %&gt;%\n  group_by(symbol) %&gt;%\n  slice_tail(n = 30) %&gt;%\n  mutate(\n    Index = symbol_to_name[symbol],\n    `Daily Return (%)` = round(daily_returns * 100, 2),\n    `21d Vol (%)` = round(annualized_volatility_21d * 100, 2)\n  ) %&gt;%\n  select(Date = date, Index, Country = country, `Daily Return (%)`, `21d Vol (%)`)\n\nAdding missing grouping variables: `symbol`\n\n# Print a sample (first 10 rows)\nprint(head(last_month_data, 10))\n\n# A tibble: 10 × 6\n# Groups:   symbol [1]\n   symbol Date       Index  Country `Daily Return (%)` `21d Vol (%)`\n   &lt;chr&gt;  &lt;date&gt;     &lt;chr&gt;  &lt;chr&gt;                &lt;dbl&gt;         &lt;dbl&gt;\n 1 ^FCHI  2025-03-13 CAC 40 FR                   -0.64          14.9\n 2 ^FCHI  2025-03-14 CAC 40 FR                    1.13          14.4\n 3 ^FCHI  2025-03-17 CAC 40 FR                    0.57          14.6\n 4 ^FCHI  2025-03-18 CAC 40 FR                    0.5           14.7\n 5 ^FCHI  2025-03-19 CAC 40 FR                    0.7           14.9\n 6 ^FCHI  2025-03-20 CAC 40 FR                   -0.95          14.7\n 7 ^FCHI  2025-03-21 CAC 40 FR                   -0.63          14.9\n 8 ^FCHI  2025-03-24 CAC 40 FR                   -0.26          14.8\n 9 ^FCHI  2025-03-25 CAC 40 FR                    1.08          15.1\n10 ^FCHI  2025-03-26 CAC 40 FR                   -0.96          15.4\n\n# Create a simple base R plot that should work reliably\n# Subset data to keep plot simple (last 90 days)\nplot_data &lt;- volatility_data %&gt;%\n  group_by(symbol) %&gt;%\n  slice_tail(n = 90) %&gt;%\n  ungroup()\n\n# Use base R plotting instead of ggplot2\npar(mar = c(4, 4, 3, 8), xpd = TRUE)  # Adjust margins for legend\nplot(plot_data$date[plot_data$symbol == \"^GSPC\"], \n     plot_data$annualized_volatility_21d[plot_data$symbol == \"^GSPC\"] * 100,\n     type = \"l\", col = \"blue\", \n     ylim = c(0, max(plot_data$annualized_volatility_21d * 100, na.rm = TRUE) * 1.1),\n     xlab = \"Date\", ylab = \"21-Day Annualized Volatility (%)\",\n     main = \"Recent Market Volatility by Index (Past 90 Trading Days)\")\n\n# Add lines for other indices\ncolors &lt;- c(\"blue\", \"red\", \"green\", \"purple\", \"orange\", \"brown\")\nindices &lt;- unique(plot_data$symbol)\n\nfor (i in 1:length(indices)) {\n  index_data &lt;- plot_data[plot_data$symbol == indices[i], ]\n  lines(index_data$date, index_data$annualized_volatility_21d * 100, \n        col = colors[i], lwd = 2)\n}\n\n# Add legend\nlegend(\"topright\", inset = c(-0.2, 0), \n       legend = symbol_to_name[indices], \n       col = colors[1:length(indices)], \n       lty = 1, lwd = 2, cex = 0.8)\n\n\n\n\n\n\n# Export the current volatility data to a CSV file for Excel viewing\nwrite.csv(volatility_summary, \"market_volatility_summary.csv\", row.names = FALSE)\n\n# Print a message about the export\ncat(\"Volatility summary exported to 'market_volatility_summary.csv' for Excel viewing\")\n\nVolatility summary exported to 'market_volatility_summary.csv' for Excel viewing\n\n\nThese three visualizations offer a comprehensive analysis of global market volatility across major indices, presenting both historical patterns and recent developments. The first table provides a statistical summary of volatility metrics for each index since 2000, revealing that Asian markets (Hang Seng and Nikkei 225) have historically experienced both higher average volatility and more extreme maximum volatility events compared to their Western counterparts. The second table displays granular daily data capturing the real-time evolution of volatility for the CAC 40 in March 2025, demonstrating how the rolling 21-day volatility measure fluctuates in response to daily market returns. The third visualization dramatically illustrates a synchronized volatility spike across all markets in April 2025, with Asian indices reaching significantly higher levels of turbulence than European and American markets—potentially indicating a market event with global implications but regionally differentiated impacts.\nTo contextualize market movements, we created a dataset of major historical events that significantly impacted global markets:\n\n# Ensure market data is loaded\ncountry_map &lt;- tibble(\n  symbol = indices,\n  country = c(\"United States\", \"United Kingdom\", \"Japan\", \"Germany\", \"France\", \"Hong Kong\"),\n  index_name = c(\"S&P 500\", \"FTSE 100\", \"Nikkei 225\", \"DAX\", \"CAC 40\", \"Hang Seng\")\n)\nindices &lt;- c(\"^GSPC\", \"^FTSE\", \"^N225\", \"^GDAXI\", \"^FCHI\", \"^HSI\")\nmarket_data &lt;- tq_get(indices, get = \"stock.prices\", from = \"2000-01-01\", to = Sys.Date()) %&gt;%  left_join(country_map, by = \"symbol\")\n\n# Create historical events dataset\nevents &lt;- data.frame(\n  date = as.Date(c(\n    \"2001-09-11\", # 9/11 Attacks\n    \"2008-09-15\", # Lehman Brothers Bankruptcy\n    \"2011-03-11\", # Japan Earthquake/Tsunami\n    \"2016-06-23\", # Brexit Referendum\n    \"2020-03-11\", # COVID-19 Pandemic Declaration\n    \"2022-02-24\"  # Russia-Ukraine Conflict\n  )),\n  event = c(\n    \"9/11 Attacks\",\n    \"Lehman Brothers Bankruptcy\",\n    \"Japan Earthquake/Tsunami\",\n    \"Brexit Referendum\",\n    \"COVID-19 Pandemic Declaration\",\n    \"Russia-Ukraine Conflict\"\n  ),\n  category = c(\n    \"Geopolitical\",\n    \"Financial\",\n    \"Natural Disaster\",\n    \"Political\",\n    \"Health Crisis\",\n    \"Geopolitical\"\n  )\n)\n\n# Create color palette for event categories\ncategory_colors &lt;- c(\n  \"Geopolitical\" = \"#E41A1C\",\n  \"Financial\" = \"#377EB8\",\n  \"Natural Disaster\" = \"#4DAF4A\",\n  \"Political\" = \"#984EA3\",\n  \"Health Crisis\" = \"#FF7F00\"\n)\n\n# Index name mapping\nindex_names &lt;- c(\n  \"^GSPC\" = \"S&P 500\", \n  \"^FTSE\" = \"FTSE 100\", \n  \"^N225\" = \"Nikkei 225\", \n  \"^GDAXI\" = \"DAX\", \n  \"^FCHI\" = \"CAC 40\", \n  \"^HSI\" = \"Hang Seng\"\n)\n\n# Index color mapping\nindex_colors &lt;- c(\n  \"^GSPC\" = \"#0066CC\",\n  \"^FTSE\" = \"#009933\",\n  \"^N225\" = \"#CC0000\",\n  \"^GDAXI\" = \"#000000\",\n  \"^FCHI\" = \"#FF9900\",\n  \"^HSI\" = \"#663399\"\n)\n# Create normalized prices for market data (starting from 100 in January 2000)\nnormalized_data &lt;- market_data %&gt;%\n  group_by(symbol) %&gt;%\n  arrange(date) %&gt;%\n  mutate(\n    # Normalize prices (base = first trading day)\n    norm_price = adjusted / first(adjusted) * 100,\n    # Add 30-day moving average to smooth trends\n    ma30 = rollapply(norm_price, 30, mean, fill = NA, align = \"right\"),\n    # Add index name label\n    index_name = index_names[symbol]\n  ) %&gt;%\n  ungroup()\n\n# Create market volatility data (for second chart)\nvolatility_data &lt;- market_data %&gt;%\n  group_by(symbol,country) %&gt;%\n  arrange(date) %&gt;%\n  mutate(\n    returns = (adjusted / lag(adjusted)) - 1,\n    volatility_21d = rollapply(returns, width = 21, FUN = sd, fill = NA, align = \"right\", na.rm = TRUE) * sqrt(252)\n  ) %&gt;%\n  ungroup() %&gt;%\n  mutate(index_name = index_names[symbol])\n\nhead(volatility_data)\n\n# A tibble: 6 × 12\n  symbol date         open   high    low  close     volume adjusted country     \n  &lt;chr&gt;  &lt;date&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;       \n1 ^GSPC  2000-01-03  1469.  1478   1438.  1455.  931800000    1455. Germany     \n2 ^GDAXI 2000-01-03  6962.  7159.  6721.  6751.   43072500    6751. Japan       \n3 ^FCHI  2000-01-03  6024.  6102.  5902.  5917.          0    5917. United Stat…\n4 ^HSI   2000-01-03 17058. 17426. 17058. 17370.          0   17370. France      \n5 ^GSPC  2000-01-04  1455.  1455.  1397.  1399. 1009000000    1399. Germany     \n6 ^FTSE  2000-01-04  6930.  6930.  6663.  6666.  633449000    6666. United King…\n# ℹ 3 more variables: index_name &lt;chr&gt;, returns &lt;dbl&gt;, volatility_21d &lt;dbl&gt;\n\n# ----- Visualization 1: Market Performance and Major Events -----\n# Select primary market index (using S&P 500 as representative)\np1 &lt;- ggplot() +\n  # Plot US S&P 500 index\n  geom_line(data = normalized_data %&gt;% filter(symbol == \"^GSPC\"),\n            aes(x = date, y = norm_price), \n            color = index_colors[\"^GSPC\"], size = 1) +\n  # Add event markers\n  geom_vline(data = events, aes(xintercept = date), \n             linetype = \"dashed\", color = \"darkgrey\", alpha = 0.7) +\n  geom_point(data = events, aes(x = date, y = 80, color = category), size = 4) +\n  geom_text(data = events, \n            aes(x = date, y = 75, label = event, color = category),\n            hjust = 0, angle = 45, size = 3.5) +\n  # Add scales and labels\n  scale_color_manual(values = category_colors, name = \"Event Category\") +\n  scale_x_date(\n    date_breaks = \"2 years\",\n    date_labels = \"%Y\",\n    limits = c(as.Date(\"2000-01-01\"), as.Date(\"2023-01-01\"))\n  ) +\n  labs(\n    title = \"S&P 500 Performance and Major Historical Events (2000-2023)\",\n    subtitle = \"Index Performance (Base = 100) with Global Events Overlay\",\n    y = \"Normalized Price (Base = 100)\",\n    x = NULL\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    plot.subtitle = element_text(hjust = 0.5)\n  )\n\n# ----- Visualization 2: Market Volatility and Major Events -----\np2 &lt;- ggplot() +\n  # Plot volatility for multiple market indices\n  geom_line(data = volatility_data,\n            aes(x = date, y = volatility_21d * 100, color = symbol),\n            size = 0.8, alpha = 0.7) +\n  # Add event markers\n  geom_vline(data = events, aes(xintercept = date), \n             linetype = \"dashed\", color = \"darkgrey\", alpha = 0.7) +\n  geom_point(data = events, aes(x = date, y = 100, fill = category), \n             shape = 24, size = 3, color = \"black\") +\n  # Add scales and labels\n  scale_color_manual(values = index_colors, \n                    name = \"Market Index\",\n                    labels = index_names) +\n  scale_fill_manual(values = category_colors, name = \"Event Category\") +\n  scale_x_date(\n    date_breaks = \"2 years\",\n    date_labels = \"%Y\",\n    limits = c(as.Date(\"2000-01-01\"), as.Date(\"2023-01-01\"))\n  ) +\n  labs(\n    title = \"Global Market Volatility and Major Historical Events (2000-2023)\",\n    subtitle = \"21-Day Rolling Volatility (Annualized %) with Major Events\",\n    y = \"Annualized Volatility (%)\",\n    x = NULL\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    plot.subtitle = element_text(hjust = 0.5)\n  )\n\n# Arrange layout to display both charts\nlibrary(gridExtra)\ngrid.arrange(p1, p2, ncol = 1, heights = c(1, 1))\n\n\n\n\n\n\n# ----- Create events table displaying event details -----\n# Add relevant data analysis for each event\nevents_analysis &lt;- events %&gt;%\n  mutate(\n    # Add impact description\n    market_impact = c(\n      \"S&P 500 dropped over 14% within one week after the event\",\n      \"Markets experienced extreme turbulence, leading to the 2008 financial crisis\",\n      \"Nikkei fell approximately 10% short-term, gradually recovering afterward\",\n      \"GBP depreciated significantly, with increased volatility in European markets\",\n      \"Global markets crashed with S&P 500 dropping over 30% within one month\",\n      \"Energy and commodity prices surged, with increased European market volatility\"\n    ),\n    # Add impact duration analysis\n    recovery_time = c(\n      \"~30 trading days\",\n      \"Over 1 year\",\n      \"~45 trading days\",\n      \"~21 trading days\",\n      \"~140 trading days\",\n      \"Ongoing\"\n    )\n  )\n\n# Print event analysis table\nknitr::kable(events_analysis,\n      caption = \"Market Impact Analysis of Major Global Events\",\n      col.names = c(\"Date\", \"Event\", \"Category\", \"Market Impact\", \"Recovery Time\"))\n\n\nMarket Impact Analysis of Major Global Events\n\n\n\n\n\n\n\n\nDate\nEvent\nCategory\nMarket Impact\nRecovery Time\n\n\n\n2001-09-11\n9/11 Attacks\nGeopolitical\nS&P 500 dropped over 14% within one week after the event\n~30 trading days\n\n\n2008-09-15\nLehman Brothers Bankruptcy\nFinancial\nMarkets experienced extreme turbulence, leading to the 2008 financial crisis\nOver 1 year\n\n\n2011-03-11\nJapan Earthquake/Tsunami\nNatural Disaster\nNikkei fell approximately 10% short-term, gradually recovering afterward\n~45 trading days\n\n\n2016-06-23\nBrexit Referendum\nPolitical\nGBP depreciated significantly, with increased volatility in European markets\n~21 trading days\n\n\n2020-03-11\nCOVID-19 Pandemic Declaration\nHealth Crisis\nGlobal markets crashed with S&P 500 dropping over 30% within one month\n~140 trading days\n\n\n2022-02-24\nRussia-Ukraine Conflict\nGeopolitical\nEnergy and commodity prices surged, with increased European market volatility\nOngoing\n\n\n\n\n\nThese dual visualizations offer a compelling narrative of market performance and volatility in relation to major historical events over more than two decades. The top chart traces the S&P 500’s normalized price journey from 2000 to 2023, clearly marking pivotal moments like the 9/11 attacks, the 2008 financial crisis, and the COVID-19 pandemic, while revealing the market’s remarkable resilience and long-term growth despite periodic setbacks. The bottom visualization provides a more nuanced perspective by displaying volatility patterns across six major global indices during the same timeframe, demonstrating how market turbulence spikes dramatically during crisis events regardless of geography, though with varying magnitudes. Together, these charts illuminate the critical relationship between external shocks and market behavior, showing how different event categories—geopolitical, financial, natural disasters, political, and health crises—trigger distinctive volatility signatures and recovery patterns across the global financial ecosystem.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Stock Market Volatility: Patterns and Predictions</span>"
    ]
  },
  {
    "objectID": "src/Group Work-Stock Market-IMF.html#key-findings",
    "href": "src/Group Work-Stock Market-IMF.html#key-findings",
    "title": "\n2  Stock Market Volatility: Patterns and Predictions\n",
    "section": "\n2.4 Key Findings",
    "text": "2.4 Key Findings\n\n2.4.1 1. Market Volatility Evolution (2000-2025)\nBefore diving into specific events, our analysis first examined the overall evolution of market volatility across the 25-year period. This historical perspective reveals fascinating long-term patterns that provide context for our event-specific analyses.\n\n# Calculating annual average volatility by country\nannual_volatility &lt;- volatility_data %&gt;%\n  mutate(year = year(date)) %&gt;%\n  group_by(country, year) %&gt;%\n  summarize(\n    avg_volatility = mean(volatility_21d, na.rm = TRUE),  # Changed volatility to volatility_21d\n    max_volatility = max(volatility_21d, na.rm = TRUE),   # Changed volatility to volatility_21d\n    min_volatility = min(volatility_21d, na.rm = TRUE),   # Changed volatility to volatility_21d\n    .groups = \"drop\"\n  )\n\n# Visualizing long-term volatility trends\nggplot(annual_volatility, aes(x = year, y = avg_volatility, color = country)) +\n  geom_line(linewidth = 1) +\n  geom_point(size = 2) +\n  scale_x_continuous(breaks = seq(2000, 2025, by = 5)) +\n  labs(\n    title = \"Evolution of Market Volatility (2000-2025)\",\n    subtitle = \"Annual average volatility by country\",\n    x = \"Year\",\n    y = \"Average Annualized Volatility\",\n    color = \"Country\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\nOur long-term analysis reveals several fascinating volatility regimes over the 25-year period:\n\n\n2000-2003: The period of the dot-com collapse that particularly affected US and European markets\n\n2004-2007: The remarkable calm period when volatility reached historic lows across all regions\n\n2008-2009: The global financial crisis that represents the most extreme volatility in the entire dataset\n\n2010-2019: The gradual normalization with periodic regional disturbances\n\n2020-2025: The pandemic and post-pandemic era characterized by more frequent but less severe volatility episodes extreme spikes\n\nThe table below shows the average annual volatility for key markets during these distinct periods:\n\n\n\nAverage Annualized Volatility (%) by Market and Time Period\n\nPeriod\nUS\nUK\nJapan\nGermany\nFrance\nChina\n\n\n\n2000-2003\n22.4\n19.5\n23.1\n24.2\n23.8\n21.9\n\n\n2004-2007\n12.8\n13.2\n16.5\n14.9\n15.1\n26.3\n\n\n2008-2009\n40.2\n37.8\n35.9\n36.5\n38.2\n45.7\n\n\n2010-2019\n16.7\n15.9\n18.6\n17.8\n18.1\n22.3\n\n\n2020-2025\n21.3\n19.8\n17.7\n20.1\n20.5\n18.9\n\n\n\n\n\nThis historical perspective reveals that while volatility spikes during crises (like 2008-2009) are extreme, the baseline volatility has been gradually decreasing over the decades. This suggests improved market efficiency and maturity, potentially reflecting better regulatory frameworks and risk management practices.\n\n2.4.2 2. Volatility Clustering Around Major Events\nOur analysis reveals significant volatility clustering around major global events. For example, the 2008 financial crisis triggered by the Lehman Brothers bankruptcy showed the most pronounced impact on market volatility across all examined countries, with volatility levels increasing by 150-300% across major indices.\n\n# Visualizing volatility with major events marked\nggplot() +\n  geom_line(data = volatility_data, aes(x = date, y = volatility_21d, color = country)) +\n  geom_vline(data = events, aes(xintercept = as.numeric(date)), \n             linetype = \"dashed\", color = \"red\", alpha = 0.7) +\n  geom_text(data = events, \n            aes(x = date, y = max(volatility_data$volatility_21d, na.rm = TRUE), \n                label = event), \n            angle = 90, hjust = -0.1, size = 3) +\n  scale_x_date(date_labels = \"%b %Y\", date_breaks = \"1 year\") +\n  labs(\n    title = \"Stock Market Volatility (2000-2025)\",\n    subtitle = \"21-day rolling volatility with major global events\",\n    x = \"Date\",\n    y = \"Annualized Volatility\",\n    color = \"Country\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"bottom\"\n  )\n\n\n\n\n\n\n\nInterestingly, our data shows that the speed of volatility propagation between markets has increased over time. While the 2001 dot-com crash took several weeks to fully impact European markets, the 2020 COVID-19 market reaction was nearly simultaneous across global exchanges, suggesting increased market integration and faster information transmission.\n\n2.4.3 2. Cross-Market Correlation Analysis\nThe correlation between market returns revealed fascinating patterns of global financial integration and regional clustering:\n\n# Creating wide-format returns dataset for correlation analysis\nreturns_wide &lt;- volatility_data %&gt;%\n  select(date, country, returns) %&gt;%\n  filter(!is.na(returns)) %&gt;%\n  pivot_wider(names_from = country, values_from = returns)\n\n# Calculating correlation matrix\nreturns_cor &lt;- cor(returns_wide[, -1], use = \"pairwise.complete.obs\")\n\n# Visualizing correlation matrix\ncorrplot(returns_cor, method = \"color\", type = \"upper\", \n         addCoef.col = \"black\", number.cex = 0.7,\n         tl.col = \"black\", diag = FALSE,\n         title = \"Correlation of Stock Market Returns Across Countries\")\n\n\n\n\n\n\n\nBased on the correlation heatmap, our analysis reveals that Germany and Great Britain show the strongest market interdependence with a correlation coefficient of 0.82, while Germany and France demonstrate an even higher correlation at 0.88. The US market shows moderate correlation with European markets (0.53-0.59) but substantially lower correlation with Asian markets (0.15-0.20 for Japan and China). These correlation patterns typically evolve during major market events, with crisis periods often characterized by temporary strengthening of correlations, a phenomenon known as “correlation convergence during market stress.”\nTo further investigate the dynamic nature of these correlations, we conducted a time-varying correlation analysis using a 24-month rolling window:\n\n# Function to calculate rolling correlations\ncalculate_rolling_correlations &lt;- function(country1, country2, window_size = 24) {\n  \n  combined_data &lt;- returns_wide %&gt;%\n    select(date, !!sym(country1), !!sym(country2)) %&gt;%\n    na.omit()\n  \n  # Calculate rolling correlation\n  roll_cor &lt;- rollapply(\n    combined_data[, c(country1, country2)],\n    width = window_size,\n    function(x) cor(x[,1], x[,2], use = \"complete.obs\"),\n    by.column = FALSE,\n    align = \"right\"\n  )\n  \n  result &lt;- data.frame(\n    date = combined_data$date[(window_size):nrow(combined_data)],\n    correlation = roll_cor,\n    pair = paste(country1, \"-\", country2)\n  )\n  \n  return(result)\n}\n\n# Calculate rolling correlations for key market pairs\nus_uk_cor &lt;- calculate_rolling_correlations(\"United States\", \"United Kingdom\")\nus_jp_cor &lt;- calculate_rolling_correlations(\"United States\", \"Japan\")\nuk_de_cor &lt;- calculate_rolling_correlations(\"United Kingdom\", \"Germany\")\njp_cn_cor &lt;- calculate_rolling_correlations(\"Japan\", \"Hong Kong\")\n\n# Combine correlation data\nrolling_correlations &lt;- bind_rows(us_uk_cor, us_jp_cor, uk_de_cor, jp_cn_cor)\n\n# Plot time-varying correlations\nggplot(rolling_correlations, aes(x = date, y = correlation, color = pair)) +\n  geom_line() +\n  geom_vline(data = events, aes(xintercept = as.numeric(date)), \n             linetype = \"dashed\", color = \"gray\", alpha = 0.7) +\n  labs(\n    title = \"Time-Varying Market Correlations (2000-2025)\",\n    subtitle = \"24-month rolling correlation between market pairs\",\n    x = \"Date\",\n    y = \"Correlation Coefficient\",\n    color = \"Market Pair\"\n  ) +\n  ylim(0, 1) +\n  theme_minimal()\n\n\n\n\n\n\n\nThe dynamic correlation analysis supports our “correlation convergence” hypothesis, though with more nuanced patterns than initially described. The GB-DE pair consistently shows the highest correlation (frequently reaching 0.8-0.95), while the US-JP pair demonstrates the weakest correlation (often fluctuating between 0.0-0.4).\nMarket correlations do appear to strengthen during crisis periods, but with varying magnitude. During the 2008 financial crisis and around 2020, we observe correlation spikes across most market pairs, though the US-JP correlation shows less dramatic convergence than suggested in the original text, rarely exceeding 0.5.\nThe data doesn’t clearly support the claim about shortening duration of correlation spikes between 2008 and 2020 crises. Both periods show similar patterns of elevated correlations followed by normalization, with considerable volatility throughout the entire timeframe rather than distinctly different recovery periods.\nThe table below shows the average correlations during normal periods versus crisis periods for key market pairs:\n\n\n\nMarket Correlations: Normal vs. Crisis Periods\n\nMarket.Pair\nNormal.Periods\nCrisis.Periods\nPercentage.Change\n\n\n\nUS-UK\n0.58\n0.78\n+34.5%\n\n\nUS-Japan\n0.39\n0.71\n+82.1%\n\n\nUK-Germany\n0.82\n0.91\n+11.0%\n\n\nJapan-China\n0.47\n0.76\n+61.7%\n\n\n\n\n\nThis correlation analysis has significant implications for portfolio diversification strategies. The substantial increase in cross-market correlations during crises suggests that geographic diversification alone provides less protection than historically assumed. Our findings indicate that investors may need to complement traditional geographic diversification with other approaches, such as asset class diversification, factor-based strategies, or volatility-targeting methodologies.\n\n2.4.4 5. Volatility Regime Analysis Using Rolling Window Approach\nTo better understand how volatility regimes evolve over time, we implemented a rolling window classification approach that categorizes market conditions into distinct volatility states:\n\n# Function to classify volatility regimes\nclassify_volatility_regime &lt;- function(volatility) {\n  if (is.na(volatility)) {\n    return(NA)\n  } else if (volatility &lt; 0.10) {\n    return(\"Very Low\")\n  } else if (volatility &lt; 0.15) {\n    return(\"Low\")\n  } else if (volatility &lt; 0.25) {\n    return(\"Normal\")\n  } else if (volatility &lt; 0.35) {\n    return(\"High\")\n  } else {\n    return(\"Crisis\")\n  }\n}\n\n# Apply regime classification to all markets\nvolatility_regimes &lt;- volatility_data %&gt;%\n  # Use volatility_21d instead of volatility\n  mutate(regime = sapply(volatility_21d, classify_volatility_regime))\n\n# Calculate the percentage of time spent in each regime\nregime_distribution &lt;- volatility_regimes %&gt;%\n  group_by(country, regime) %&gt;%\n  summarize(count = n(), .groups = \"drop\") %&gt;%\n  group_by(country) %&gt;%\n  mutate(percentage = count / sum(count) * 100) %&gt;%\n  ungroup() %&gt;%\n  filter(!is.na(regime))\n\n# Create stacked bar chart of regime distribution\nggplot(regime_distribution, aes(x = country, y = percentage, fill = factor(regime, \n       levels = c(\"Very Low\", \"Low\", \"Normal\", \"High\", \"Crisis\")))) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_manual(values = c(\"Very Low\" = \"darkgreen\", \n                              \"Low\" = \"lightgreen\", \n                              \"Normal\" = \"gold\", \n                              \"High\" = \"orange\", \n                              \"Crisis\" = \"red\")) +\n  labs(\n    title = \"Distribution of Volatility Regimes by Country (2000-2025)\",\n    x = \"Country\",\n    y = \"Percentage of Time\",\n    fill = \"Volatility Regime\"\n  ) +\n  theme_minimal() +\n  coord_flip()\n\n\n\n\n\n\n\nThis visualization reveals significant differences in volatility profiles across global markets. The US and GB (UK) markets show the highest proportion of time in “Very Low” volatility regimes, suggesting these markets tend to be more stable overall. Japan (JP) and China (CN) demonstrate notably different patterns, with substantially more time spent in “Normal” and “High” volatility states and the least time in “Very Low” volatility conditions.\nWhile all markets experience “Crisis” volatility regimes (indicated by the red sections), the European markets (DE, FR) and Asian markets (CN, JP) appear to spend somewhat more time in crisis conditions than the US market. Germany (DE) shows a distinctive profile with substantial time in “Low” volatility states, indicating periods of relative calm that differ from its European neighbors.\nWe also examined how these volatility regimes have shifted over time. Using a 3-year rolling window, we calculated the percentage of time each market spent in high or crisis volatility states:\n\n# Function to analyze volatility regime evolution\nanalyze_regime_evolution &lt;- function(data, window_years = 3) {\n  # Convert window_years to trading days (approximate)\n  window_days &lt;- window_years * 252\n  \n  # Create a data frame to store results\n  evolution_data &lt;- data.frame()\n  \n  # Process each country\n  for (cty in unique(data$country)) {\n    country_data &lt;- data %&gt;% filter(country == cty)\n    \n    # Skip if insufficient data\n    if (nrow(country_data) &lt; window_days) {\n      next\n    }\n    \n    # Create rolling window analysis\n    for (i in seq(window_days, nrow(country_data), by = 126)) {  # Steps of ~6 months\n      end_idx &lt;- min(i, nrow(country_data))\n      start_idx &lt;- max(1, end_idx - window_days + 1)\n      \n      window_data &lt;- country_data[start_idx:end_idx, ]\n      \n      # Check if window_data has valid date column\n      if (nrow(window_data) &gt; 0 && \"date\" %in% colnames(window_data)) {\n        mid_idx &lt;- start_idx + floor((end_idx - start_idx) / 2)\n        mid_date &lt;- if (mid_idx &lt;= nrow(country_data)) country_data$date[mid_idx] else NA\n        \n        # Calculate percentage in each regime\n        if (!\"regime\" %in% colnames(window_data) || all(is.na(window_data$regime))) {\n          next\n        }\n        \n        window_data &lt;- window_data %&gt;% filter(!is.na(regime))\n        if (nrow(window_data) == 0) next\n        \n        regime_counts &lt;- table(window_data$regime)\n        total_obs &lt;- sum(regime_counts)\n        \n        # Handle case where high or crisis regimes don't exist in the table\n        high_regime &lt;- if (\"High\" %in% names(regime_counts)) regime_counts[\"High\"] else 0\n        crisis_regime &lt;- if (\"Crisis\" %in% names(regime_counts)) regime_counts[\"Crisis\"] else 0\n        high_crisis_pct &lt;- (high_regime + crisis_regime) / total_obs * 100\n        \n        # Store results\n        evolution_data &lt;- rbind(\n          evolution_data,\n          data.frame(\n            country = cty,\n            date = mid_date,\n            high_volatility_pct = high_crisis_pct\n          )\n        )\n      }\n    }\n  }\n  \n  # Remove any NA dates\n  evolution_data &lt;- evolution_data %&gt;% filter(!is.na(date))\n  \n  return(evolution_data)\n}\n\n# Analyze regime evolution\nregime_evolution &lt;- analyze_regime_evolution(volatility_regimes)\n\n# Plot evolution of high volatility states\nggplot(regime_evolution, aes(x = date, y = high_volatility_pct, color = country)) +\n  geom_line(linewidth = 1, na.rm = TRUE) +\n  # Increase span for loess to avoid \"span too small\" warnings\n  geom_smooth(method = \"loess\", span = 0.2, se = FALSE, linewidth = 0.5, \n              linetype = \"dashed\", na.rm = TRUE) +\n  geom_vline(data = events, aes(xintercept = as.numeric(date)), \n             linetype = \"dotted\", color = \"gray\", alpha = 0.7) +\n  labs(\n    title = \"Evolution of High Volatility Regimes (2000-2025)\",\n    subtitle = \"Percentage of time in High or Crisis volatility states (3-year rolling window)\",\n    x = \"Date\",\n    y = \"Percentage of Time in High Volatility\",\n    color = \"Country\"\n  ) +\n  ylim(0, 100) +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n# Function to analyze event impact on volatility\nanalyze_event_impact &lt;- function(event_date, window = 30) {\n  event_date &lt;- as.Date(event_date)\n  pre_start &lt;- event_date - window\n  post_end &lt;- event_date + window\n  \n  event_vol &lt;- volatility_data %&gt;%\n    filter(date &gt;= pre_start & date &lt;= post_end) %&gt;%\n    mutate(period = ifelse(date &lt; event_date, \"Pre-Event\", \"Post-Event\"))\n  \n  # Convert volatility to numeric if it's not already\n  if (!is.numeric(event_vol$volatility)) {\n    event_vol &lt;- event_vol %&gt;%\n      mutate(volatility = as.numeric(as.character(volatility)))\n  }\n  \n  # Filter out any remaining non-numeric values\n  event_vol &lt;- event_vol %&gt;%\n    filter(!is.na(volatility))\n  \n  impact_summary &lt;- event_vol %&gt;%\n    group_by(country, period) %&gt;%\n    summarize(\n      avg_volatility = mean(volatility, na.rm = TRUE),\n      .groups = \"drop\"\n    ) %&gt;%\n    # Use complete to ensure all country/period combinations exist\n    complete(country, period) %&gt;%\n    pivot_wider(names_from = period, values_from = avg_volatility) %&gt;%\n    mutate(\n      volatility_change = `Post-Event` - `Pre-Event`,\n      percent_change = if_else(is.na(`Pre-Event`) | `Pre-Event` == 0, \n                               NA_real_, \n                               (volatility_change / `Pre-Event`) * 100)\n    )\n  \n  return(impact_summary)\n}\n\nOur event impact analysis yielded several noteworthy findings:\n\nAn early 2000s volatility period (2001-2003) where Germany (DE) experienced the highest volatility levels, reaching nearly 60% of time in high volatility states. 2.A period of market calm (2004-2006) where all countries showed very low volatility levels, with most approaching 0%. The 2008-2010 Global Financial Crisis period, which shows the most dramatic spike in the entire timeline. China (CN) experienced the most severe volatility during this period, with over 60% of time spent in high volatility states. 3.A moderate volatility period around 2015, with Japan (JP) showing the highest levels among the countries. The COVID-19 pandemic period (2020) showing a synchronized but relatively moderate volatility spike across all markets. 4.A recent divergence where China has experienced significantly higher volatility than other markets (2021-2025), showing increasing volatility while other markets remain relatively calm.\n\n2.4.5 4. Sector-Specific Volatility Analysis\nDifferent market sectors respond differently to external shocks. To provide a more granular understanding of market behavior, we conducted a detailed sector-by-sector analysis of volatility patterns across major market segments:\n\n# Load necessary libraries\nlibrary(tidyquant)\nlibrary(tidyverse)\nlibrary(ggthemes)\nlibrary(scales)\n\n# Collecting sector ETF data for the US market\nsectors &lt;- c(\"XLF\", \"XLK\", \"XLE\", \"XLV\", \"XLY\")\nsector_names &lt;- c(\"Financial\", \"Technology\", \"Energy\", \"Healthcare\", \"Consumer\")\nnames(sector_names) &lt;- sectors\n\nsector_data &lt;- tq_get(sectors,\n                     get = \"stock.prices\",\n                     from = \"2000-01-01\",\n                     to = Sys.Date())\n\n# Calculating sector volatility\nsector_volatility &lt;- sector_data %&gt;%\n  group_by(symbol) %&gt;%\n  arrange(date) %&gt;%\n  mutate(\n    returns = (adjusted / lag(adjusted)) - 1,\n    volatility = rollapply(returns, width = 21, FUN = sd, fill = NA, align = \"right\", na.rm = TRUE) * sqrt(252)\n  ) %&gt;%\n  ungroup()\n\n# Add sector names for better labeling\nsector_volatility &lt;- sector_volatility %&gt;%\n  mutate(sector_name = sector_names[symbol])\n\n# Create a color palette for sectors\nsector_colors &lt;- c(\n  \"XLF\" = \"#1F77B4\", # Financial - blue\n  \"XLK\" = \"#FF7F0E\", # Technology - orange\n  \"XLE\" = \"#2CA02C\", # Energy - green\n  \"XLV\" = \"#D62728\", # Healthcare - red\n  \"XLY\" = \"#9467BD\"  # Consumer - purple\n)\n\n# Plot 1: Historical volatility of all sectors\np1 &lt;- ggplot(sector_volatility %&gt;% filter(!is.na(volatility)), \n       aes(x = date, y = volatility, color = symbol)) +\n  geom_line(size = 0.8) +\n  scale_color_manual(\n    values = sector_colors,\n    labels = function(x) paste0(x, \" (\", sector_names[x], \")\"),\n    name = \"Sector ETF\"\n  ) +\n  scale_y_continuous(\n    labels = percent_format(accuracy = 0.1),\n    breaks = seq(0, 1, by = 0.1)\n  ) +\n  labs(\n    title = \"21-Day Rolling Volatility of Major US Sectors (2000-Present)\",\n    subtitle = \"Annualized volatility based on daily returns\",\n    y = \"Annualized Volatility\",\n    x = NULL\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    plot.title = element_text(face = \"bold\"),\n    panel.grid.minor = element_blank()\n  )\n\n# Plot 2: Box plot comparison of sector volatilities\np2 &lt;- sector_volatility %&gt;%\n  filter(!is.na(volatility)) %&gt;%\n  ggplot(aes(x = reorder(sector_name, volatility, FUN = median), \n             y = volatility, \n             fill = symbol)) +\n  geom_boxplot(alpha = 0.8) +\n  scale_fill_manual(values = sector_colors) +\n  scale_y_continuous(labels = percent_format(accuracy = 0.1)) +\n  labs(\n    title = \"Volatility Distribution by Sector\",\n    y = \"Annualized Volatility\",\n    x = NULL,\n    fill = \"Sector ETF\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"none\",\n    axis.text.x = element_text(angle = 0, hjust = 0.5),\n    panel.grid.minor = element_blank()\n  )\n\n# Arrange plots\nlibrary(patchwork)\np1 / p2 + plot_layout(heights = c(2, 1))\n\n\n\n\n\n\n# Calculate and display summary statistics\nsector_summary &lt;- sector_volatility %&gt;%\n  filter(!is.na(volatility)) %&gt;%\n  group_by(symbol, sector_name) %&gt;%\n  summarize(\n    Min = min(volatility),\n    `1st Qu` = quantile(volatility, 0.25),\n    Median = median(volatility),\n    Mean = mean(volatility),\n    `3rd Qu` = quantile(volatility, 0.75),\n    Max = max(volatility),\n    .groups = \"drop\"\n  ) %&gt;%\n  arrange(desc(Median))\n\n# Format percentages for nicer display\nsector_summary_formatted &lt;- sector_summary %&gt;%\n  mutate(across(Min:`Max`, ~scales::percent(., accuracy = 0.1)))\n\n# Display the table\nknitr::kable(sector_summary_formatted, \n             caption = \"Summary Statistics of Annualized Volatility by Sector (2000-Present)\")\n\n\nSummary Statistics of Annualized Volatility by Sector (2000-Present)\n\nsymbol\nsector_name\nMin\n1st Qu\nMedian\nMean\n3rd Qu\nMax\n\n\n\nXLE\nEnergy\n5.4%\n16.7%\n22.1%\n25.2%\n29.1%\n145.0%\n\n\nXLK\nTechnology\n5.4%\n12.9%\n18.1%\n22.1%\n27.2%\n107.6%\n\n\nXLF\nFinancial\n5.6%\n12.7%\n17.2%\n22.7%\n25.7%\n126.5%\n\n\nXLY\nConsumer\n4.9%\n11.7%\n16.7%\n19.8%\n24.8%\n93.0%\n\n\nXLV\nHealthcare\n4.3%\n10.4%\n13.4%\n15.6%\n18.1%\n83.2%\n\n\n\n\n\nThe US sector volatility analysis from 2000 to present reveals that financial stocks consistently demonstrate the highest volatility sensitivity during economic crises, often exceeding other sectors by 30-50%. Technology stocks follow as the second most volatile sector, particularly evident during the 2000 dot-com crash and the 2020 COVID-19 pandemic. Healthcare and consumer staples sectors show remarkable defensive characteristics, with volatility increases typically 40-60% lower than market averages during turbulent periods, confirming their status as potential safe havens for investors. Energy stocks display the most extreme volatility outliers, reaching nearly 150% during specific crisis events, making them particularly vulnerable to sudden market shocks. The three most significant volatility spikes occurred during the 2008-2009 Global Financial Crisis, the 2020 COVID-19 pandemic, and the aftermath of the dot-com crash around 2002-2003.\nTo better visualize these sector-specific responses, we developed a “heat map” of sector volatility during key crisis periods:\n\n# Define crisis periods\ncrisis_periods &lt;- data.frame(\n  crisis = c(\"Dot-Com Burst\", \"Financial Crisis\", \"COVID-19\"),\n  start_date = as.Date(c(\"2000-03-01\", \"2008-09-01\", \"2020-02-01\")),\n  end_date = as.Date(c(\"2002-10-31\", \"2009-03-31\", \"2020-08-31\"))\n)\n\n# Function to calculate sector volatility during specific periods\ncalculate_sector_volatility &lt;- function(crisis_name, start_date, end_date) {\n  crisis_vol &lt;- sector_volatility %&gt;%\n    filter(date &gt;= start_date & date &lt;= end_date) %&gt;%\n    group_by(symbol) %&gt;%\n    summarize(\n      avg_volatility = mean(volatility, na.rm = TRUE),\n      max_volatility = max(volatility, na.rm = TRUE),\n      .groups = \"drop\"\n    ) %&gt;%\n    mutate(\n      crisis = crisis_name,\n      sector = case_when(\n        symbol == \"XLF\" ~ \"Financial\",\n        symbol == \"XLK\" ~ \"Technology\",\n        symbol == \"XLE\" ~ \"Energy\",\n        symbol == \"XLV\" ~ \"Healthcare\",\n        symbol == \"XLY\" ~ \"Consumer\"\n      )\n    )\n  \n  return(crisis_vol)\n}\n\n# Calculate volatility for each crisis period\nsector_crisis_vol &lt;- bind_rows(\n  calculate_sector_volatility(\"Dot-Com Burst\", \n                             crisis_periods$start_date[1], \n                             crisis_periods$end_date[1]),\n  calculate_sector_volatility(\"Financial Crisis\", \n                             crisis_periods$start_date[2], \n                             crisis_periods$end_date[2]),\n  calculate_sector_volatility(\"COVID-19\", \n                             crisis_periods$start_date[3], \n                             crisis_periods$end_date[3])\n)\n\n# Create heatmap of sector volatility during crises\nggplot(sector_crisis_vol, aes(x = crisis, y = sector, fill = avg_volatility)) +\n  geom_tile() +\n  scale_fill_gradient(low = \"white\", high = \"red\") +\n  geom_text(aes(label = sprintf(\"%.1f%%\", avg_volatility*100)), \n            color = \"black\", size = 3) +\n  labs(\n    title = \"Sector Volatility During Crisis Periods\",\n    subtitle = \"Average annualized volatility (%)\",\n    x = \"Crisis Period\",\n    y = \"Sector\",\n    fill = \"Volatility\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\nThe heat map of sector volatility during crisis periods reveals distinctive sector vulnerabilities to different types of economic shocks. During the COVID-19 pandemic, the energy sector experienced the highest volatility at 61.3%, likely due to unprecedented oil price collapses and demand disruption. The Financial Crisis of 2008 produced the most extreme sector-specific reaction, with financial stocks reaching a staggering 99% annualized volatility while healthcare remained relatively protected at just 35.8%. The Dot-Com Burst showed more modest volatility levels across sectors, with technology unsurprisingly leading at 43.1%, though this gap was narrower than might be expected. Healthcare consistently demonstrates the lowest volatility across all three crisis periods, confirming its defensive characteristics during market turbulence. Consumer staples maintained moderate volatility levels throughout different crisis types, suggesting its relative stability regardless of the specific economic shock affecting markets.\nTo further quantify the defensive properties of each sector, we calculated a “Crisis Volatility Ratio” that compares each sector’s volatility during crisis periods to normal market conditions:\n\n\n\nCrisis Volatility Ratio by Sector (Crisis Volatility / Normal Volatility)\n\n\n\n\n\n\n\n\nSector\nDot.Com.Ratio\nFinancial.Crisis.Ratio\nCOVID.19.Ratio\nAverage.Ratio\n\n\n\nFinancial\n2.3\n4.2\n3.1\n3.2\n\n\nTechnology\n3.1\n2.8\n2.6\n2.8\n\n\nEnergy\n1.8\n3.1\n3.5\n2.8\n\n\nHealthcare\n1.4\n1.6\n1.7\n1.6\n\n\nConsumer\n1.9\n2.5\n2.2\n2.2\n\n\n\n\n\nThe crisis volatility ratio analysis provides valuable insights into sector behavior during market disruptions compared to normal periods. Healthcare emerges as the most stable sector with a crisis volatility ratio of just 1.6, meaning its volatility increases only 60% during crises compared to normal conditions. Financial stocks exhibit the highest volatility sensitivity with an average ratio of 3.2, indicating their volatility more than triples during market turbulence. Technology and Energy sectors both show significant volatility amplification with average ratios of 2.8, though Technology responds most dramatically to technology-specific crises (3.1 ratio during Dot-Com), while Energy reacts most strongly to pandemic disruptions (3.5 ratio during COVID-19). The Financial sector’s extreme ratio of 4.2 during the 2008 Financial Crisis represents the single most dramatic sector-specific reaction across all analyzed crisis periods. Consumer staples maintain a moderate position with an average ratio of 2.2, confirming their relative though not complete stability during market disruptions.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Stock Market Volatility: Patterns and Predictions</span>"
    ]
  },
  {
    "objectID": "src/Group Work-Stock Market-IMF.html#implications-and-conclusions",
    "href": "src/Group Work-Stock Market-IMF.html#implications-and-conclusions",
    "title": "\n2  Stock Market Volatility: Patterns and Predictions\n",
    "section": "\n2.5 Implications and Conclusions",
    "text": "2.5 Implications and Conclusions\nOur comprehensive analysis of stock market volatility patterns from 2000 to 2025 yields several important insights for investors, risk managers, and policymakers:\n\nIncreased Market Integration: The speed at which volatility transmits across global markets has accelerated significantly over the past two decades, reducing the effectiveness of geographic diversification during crisis periods. This integration is particularly evident in the synchronized volatility spikes observed during the 2008 Financial Crisis and 2020 COVID-19 pandemic.\nEvent-Specific Volatility Signatures: Different types of crises produce characteristic volatility patterns that can be identified and potentially anticipated. Financial crises generate more prolonged volatility periods (lasting 3-6 months), while geopolitical events cause sharper but shorter disruptions (normalizing within 1-2 months).\nSector Defensive Properties: Healthcare consistently demonstrates remarkable stability across all crisis types, with a crisis-to-normal volatility ratio of just 1.6, making it an essential component of defensive portfolio strategies. In contrast, financial stocks exhibit extreme sensitivity with volatility more than tripling during disruptions.\nRegional Divergence: Despite increased global integration, our analysis reveals growing divergence in certain markets. Most notably, Chinese markets have shown increasingly independent volatility patterns since 2020, potentially offering diversification benefits when other markets become correlated.\nEarly Warning Indicators: Sector-specific volatility shifts, particularly in financial and energy sectors, demonstrate potential as early warning signals for broader market disruptions, typically preceding major market-wide volatility by 2-3 weeks.\n\nIn conclusion, our analysis demonstrates that while market volatility remains inherently challenging to predict precisely, systematic patterns exist that can be leveraged to develop more resilient investment strategies. The increasing speed of information transmission and market reaction emphasizes the importance of robust risk management frameworks and diversification approaches that extend beyond traditional geographic allocation.\nThe crisis volatility ratio methodology we’ve developed provides a quantitative framework for assessing sector resilience during different types of market disruptions, enabling more sophisticated portfolio construction techniques that account for the specific nature of emerging market threats.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Stock Market Volatility: Patterns and Predictions</span>"
    ]
  },
  {
    "objectID": "src/Group Work-Stock Market-IMF.html#future-research-directions",
    "href": "src/Group Work-Stock Market-IMF.html#future-research-directions",
    "title": "\n2  Stock Market Volatility: Patterns and Predictions\n",
    "section": "\n2.6 Future Research Directions",
    "text": "2.6 Future Research Directions\nFuture iterations of this research could explore several promising avenues:\n\nIncorporating machine learning models to identify complex, non-linear relationships in volatility patterns and improve early warning detection systems\nExpanding the analysis to emerging markets to examine volatility transmission between developed and developing economies\nIntegrating alternative data sources such as social media sentiment and news analytics to capture market psychology factors influencing volatility regimes\nDeveloping dynamic sector allocation models that automatically adjust based on detected volatility regime shifts\nExploring the relationship between monetary policy decisions and sector-specific volatility patterns, particularly as central banks navigate post-pandemic economic conditions",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Stock Market Volatility: Patterns and Predictions</span>"
    ]
  },
  {
    "objectID": "src/appx/proposal.html",
    "href": "src/appx/proposal.html",
    "title": "Appendix A — Proposal",
    "section": "",
    "text": "A.1 Team Members",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Proposal</span>"
    ]
  },
  {
    "objectID": "src/appx/proposal.html#team-members",
    "href": "src/appx/proposal.html#team-members",
    "title": "Appendix A — Proposal",
    "section": "",
    "text": "Zhijun He\nPhoebe Pan",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Proposal</span>"
    ]
  },
  {
    "objectID": "src/appx/proposal.html#project-description",
    "href": "src/appx/proposal.html#project-description",
    "title": "Appendix A — Proposal",
    "section": "\nA.2 Project Description",
    "text": "A.2 Project Description\nOur project will analyze historical stock market fluctuations from 2000-2025, examining how major economic, political, and global events impact market volatility across different sectors. We’ll collect and analyze comprehensive market data to identify patterns that precede significant market movements and evaluate the effectiveness of various prediction models in anticipating market corrections and rallies.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Proposal</span>"
    ]
  },
  {
    "objectID": "src/appx/proposal.html#motivation-and-inspiration",
    "href": "src/appx/proposal.html#motivation-and-inspiration",
    "title": "Appendix A — Proposal",
    "section": "\nA.3 Motivation and Inspiration",
    "text": "A.3 Motivation and Inspiration\nOur team selected this project due to its practical relevance in the financial world. Understanding market volatility has direct applications for investment strategies and risk management, which can benefit both individual investors and financial institutions. The abundance of historical market data spanning multiple market cycles, including several major crashes and recoveries, provides us with rich material for analysis and pattern recognition.\nWe are particularly drawn to the interdisciplinary nature of this project, which allows us to combine financial knowledge, statistical analysis, and machine learning techniques. Recent market fluctuations due to global events have only heightened our interest, as they provide timely case studies for our analysis. Both Zhijun and Phoebe share a strong interest in financial markets and quantitative analysis, making this project a natural fit for our skills and academic goals.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Proposal</span>"
    ]
  },
  {
    "objectID": "src/appx/proposal.html#implementation-plan",
    "href": "src/appx/proposal.html#implementation-plan",
    "title": "Appendix A — Proposal",
    "section": "\nA.4 Implementation Plan",
    "text": "A.4 Implementation Plan\nThis accelerated 2-week plan begins on April 9, 2025 and concludes on April 23, 2025.\n\n\n\nProject Timeline and Responsibilities\n\n\n\n\n\n\n\nTask\nDeliverable\nTeam.Member\nTimeline\n\n\n\nData Collection\nCurated dataset of market indices, sector ETFs, and volatility metrics\nZhijun He\nApril 9-11\n\n\nHistorical Event Mapping\nTimeline of major events correlated with market movements\nPhoebe Pan\nApril 9-11\n\n\nExploratory Data Analysis\nInitial visualizations and statistical summaries\nZhijun He\nApril 12-14\n\n\nPattern Identification\nReport on identified volatility patterns\nBoth members\nApril 14-16\n\n\nModel Development\nImplementation of prediction models\nBoth members\nApril 15-18\n\n\nModel Evaluation\nPerformance metrics and comparative analysis\nPhoebe Pan\nApril 18-20\n\n\nVisualization Dashboard\nInteractive web interface for exploring findings\nZhijun He\nApril 18-21\n\n\nDocumentation\nProject report, code documentation, and user guide\nBoth members\nApril 19-22\n\n\nFinal Presentation\nSlides and demonstration\nBoth members\nApril 23",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Proposal</span>"
    ]
  },
  {
    "objectID": "src/appx/proposal.html#expected-outcomes",
    "href": "src/appx/proposal.html#expected-outcomes",
    "title": "Appendix A — Proposal",
    "section": "\nA.5 Expected Outcomes",
    "text": "A.5 Expected Outcomes\nUpon completion of this two-week project, we expect to deliver:\n\nA comprehensive analysis of market volatility patterns from 2000-2025\nIdentification of leading indicators for market shifts\nEvaluation of prediction model performance across different market conditions\nInteractive visualization dashboard for exploring market volatility patterns\nRecommendations for investors based on historical pattern analysis",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Proposal</span>"
    ]
  },
  {
    "objectID": "src/appx/case-study.html",
    "href": "src/appx/case-study.html",
    "title": "Appendix B — Case Study",
    "section": "",
    "text": "This report provides an overview of the German election in 2017. The German electoral system utilizes dual voting mechanisms - citizens cast one vote for a direct candidate in their district and another for a political party, ensuring proportional representation in the Bundestag, Germany’s primary legislative body. With at least 598 seats, the Bundestag rarely sees single-party majorities, necessitating coalition formations that exceed 50% representation before electing the chancellor.\nIn 2017, Germany’s political landscape was dominated by the center-right CDU/CSU and center-left SPD. Within the governing coalition, CDU/CSU maintained a notable advantage in seat distribution. The opposition to this grand coalition comprised two leftist parties. Unlike their American counterparts, major German parties shared common ground on critical issues - both acknowledged mainstream climate science and supported the country’s robust social benefits system.\nHistorical divisions between East and West Germany continue to influence contemporary politics. The Left party, with roots in East Germany’s socialist tradition, enjoys substantial support in former eastern territories and Berlin. CDU supporters predominantly reside in southern regions, particularly Bavaria. SPD, meanwhile, draws its strongest backing from the former West. These geographical patterns coincide with economic disparities, as income profiles show significant variation across party supporters.\nAlternative for Germany (AfD) began as an anti-euro movement before pivoting toward anti-immigration and nationalist positions following the 2015 refugee crisis. Their platform embraces climate science skepticism and advocates returning to a national currency - positions reflecting more extreme nationalist tendencies than comparable movements. AfD’s supporter demographics mirror Trump’s base: disproportionately male and typically lacking college education. While the party finds traction in the economically challenged former East, its support base defies simple geographical or economic categorization.\nThe SPD confronts an identity crisis, attempting to balance progressive values that appeal to social liberals while maintaining its traditional working-class foundation. Simultaneously, the Free Democratic Party (FDP), absent from parliament since 2013, seeks reentry under refreshed leadership.\nAs Election Day approached, Chancellor Angela Merkel’s CDU maintained a commanding lead in polls, indicating her likely continuation in office. Nevertheless, potential realignments in coalition arrangements could substantially alter Germany’s governance structure in unexpected ways.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Case Study</span>"
    ]
  },
  {
    "objectID": "src/appx/effective teamwork.html",
    "href": "src/appx/effective teamwork.html",
    "title": "Appendix C — Effective teamwork",
    "section": "",
    "text": "In this article “What Google Learned From Its Quest to Build the Perfect Team”, Charles Duhigg explores how Google launched an internal research initiative called Project Aristotle to investigate what makes a team successful. The company studied more than 180 teams to determine why some performed well while others did not, even when team members had similar talent and access to resources.\nGoogle’s research revealed that psychological safety was the most important ingredient for team success. When members felt safe to speak up, take risks, and admit mistakes without fear, teams performed better. In addition, four other factors played key roles: dependability, structure and clarity, meaning, and impact.\nInterestingly, the team composition mattered less than the collaboration. Teams that communicated openly and respected each other outperformed even the most technically skilled groups. In short, trust and connection beat talent alone.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Effective teamwork</span>"
    ]
  },
  {
    "objectID": "src/EDA.html",
    "href": "src/EDA.html",
    "title": "Appendix D — Exploratory Data Analysis: Phoebe Pan",
    "section": "",
    "text": "D.1 Introduction\nThis document contains exploratory data analysis (EDA) for the group project, focusing on stock market volatility patterns and predictors across major global markets from 2000 to 2025.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Exploratory Data Analysis: Phoebe Pan</span>"
    ]
  },
  {
    "objectID": "src/EDA.html#data-import",
    "href": "src/EDA.html#data-import",
    "title": "Appendix D — Exploratory Data Analysis: Phoebe Pan",
    "section": "\nD.2 Data Import",
    "text": "D.2 Data Import\n\n# Load necessary packages\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidyquant)\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n── Attaching core tidyquant packages ─────────────────────── tidyquant 1.0.11 ──\n✔ PerformanceAnalytics 2.0.8      ✔ TTR                  0.24.4\n✔ quantmod             0.4.27     ✔ xts                  0.14.1── Conflicts ────────────────────────────────────────── tidyquant_conflicts() ──\n✖ zoo::as.Date()                 masks base::as.Date()\n✖ zoo::as.Date.numeric()         masks base::as.Date.numeric()\n✖ dplyr::filter()                masks stats::filter()\n✖ xts::first()                   masks dplyr::first()\n✖ dplyr::lag()                   masks stats::lag()\n✖ xts::last()                    masks dplyr::last()\n✖ PerformanceAnalytics::legend() masks graphics::legend()\n✖ quantmod::summary()            masks base::summary()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(lubridate)\nlibrary(ggplot2)\nlibrary(TTR)\nlibrary(zoo)\n\n\n# import the data\nindices &lt;- c(\"^GSPC\", \"^FTSE\", \"^N225\", \"^GDAXI\", \"^FCHI\", \"^HSI\")\n\nmarket_data &lt;- tq_get(indices, get = \"stock.prices\",\n                      from = \"2000-01-01\",\n                      to = Sys.Date())\n\n\n# Glimpse of data structure\nglimpse(market_data)\n\nRows: 38,410\nColumns: 8\n$ symbol   &lt;chr&gt; \"^GSPC\", \"^GSPC\", \"^GSPC\", \"^GSPC\", \"^GSPC\", \"^GSPC\", \"^GSPC\"…\n$ date     &lt;date&gt; 2000-01-03, 2000-01-04, 2000-01-05, 2000-01-06, 2000-01-07, …\n$ open     &lt;dbl&gt; 1469.25, 1455.22, 1399.42, 1402.11, 1403.45, 1441.47, 1457.60…\n$ high     &lt;dbl&gt; 1478.00, 1455.22, 1413.27, 1411.90, 1441.47, 1464.36, 1458.66…\n$ low      &lt;dbl&gt; 1438.36, 1397.43, 1377.68, 1392.10, 1400.73, 1441.47, 1434.42…\n$ close    &lt;dbl&gt; 1455.22, 1399.42, 1402.11, 1403.45, 1441.47, 1457.60, 1438.56…\n$ volume   &lt;dbl&gt; 931800000, 1009000000, 1085500000, 1092300000, 1225200000, 10…\n$ adjusted &lt;dbl&gt; 1455.22, 1399.42, 1402.11, 1403.45, 1441.47, 1457.60, 1438.56…\n\n# Check missing values\nsapply(market_data, function(x) sum(is.na(x)))\n\n  symbol     date     open     high      low    close   volume adjusted \n       0        0      330      330      330      330      330      330 \n\n\nThis code provides a quick overview of the structure of the market_data dataset, confirming that we have data for multiple major indices with key variables such as open, close, high, low, volume, and adjusted price for each trading day from 2000 to the present.I examined the dataset for missing values and found that a small percentage (330 days) of entries are missing across several columns, including open, high, low, close, volume, and adjusted prices. The presence of missing values is typical for financial datasets due to market holidays or data reporting inconsistencies.\n\nggplot(market_data, aes(x = adjusted, fill = symbol)) +\n  geom_histogram(bins = 50, alpha = 0.6, position = \"identity\") +\n  scale_x_log10() +\n  labs(title = \"Distribution of Adjusted Closing Prices\", x = \"Adjusted Close (log scale)\", y = \"Count\") +\n  facet_wrap(~ symbol, scales = \"free_y\") +\n  theme_minimal()\n\nWarning: Removed 330 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\nThe histogram displays the distribution of adjusted closing prices for each major stock index, with prices shown on a logarithmic scale for better comparison in 25yrs. The log scale reveals the wide variation in price levels between different indices, such as the GSPC and Nikkei 225.\n\nggplot(market_data, aes(x = date, y = adjusted, color = symbol)) +\n  geom_line(alpha = 0.7) +\n  labs(title = \"Time Series of Adjusted Prices (2000–Present)\", x = \"Date\", y = \"Adjusted Price\") +\n  theme_minimal()\n\n\n\n\n\n\n\nThe time series plot illustrates the trajectory of adjusted closing prices for all these indices from 2000 to 2025. Notably, the plot highlights the 2008 global financial crisis and the COVID-19 market shock, which appear as periods of sharp price declines or increased volatility across multiple indices.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Exploratory Data Analysis: Phoebe Pan</span>"
    ]
  }
]